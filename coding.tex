\chapter{Efficient Encoding, Decoding, and Indexing} \label{chap:coding}
The mappings described in the previous chapter are only one part of the process for associating geospatial data to cells of a 3D DGGS.
With geospatial data mapped to the domain of the grid system, the set of cells associated with the geometry of the data---and the indices of said cells---must be obtained.
As described earlier, this entire process is known as grid encoding.
Likewise, there needs to be a process to obtain the geometry of a cell (in grid space) from its index, so that the geometry can be mapped to the corresponding cell geometry in physical space.
This process is known as grid decoding.


Beyond encoding and decoding, there are also operations and queries done with a DGGS directly in grid space.
These operations often use algorithms for traversing the grid through neighbour, parent, and child relationships between cells.
Thus, queries that give these relationships for a given cell are another essential component of a fully functioning DGGS.


This chapter completes the 3D DGGS's described in the preceding chapters by providing encoding, decoding, and indexing operations for the SDOG modifications and grid extension method.
Different types of geometry typically require their own encoding algorithms.
In this thesis, we focus on point encoding as it is the most fundamental, with the encoding of more complex geometries built off this operation.
While SDOG already has hierarchical coding algorithms~\cite{yu2009sdog, yu2009coding} that are trivially adapted to work with the modified grids, we derive constant time alternatives that work for both the conventional grid and our modifications.
For completeness, we also describe algorithms for performing neighbour, parent, and child queries.
For the grid extension method, we derive these operations in such a way as to ensure interoperability and consistency between the 3D and input DGGS.


\section{SDOG}
When first introduced by Yu and Wu, the authors proposed two indexing schemes for use with SDOG~\cite{yu2009coding}.
These schemes are both based on a modified Morton code (also known as a Z-order curve)~\cite{morton1966computer}; however, one is intended for indexing a single resolution whereas the other for the full cell hierarchy.
We focus on the hierarchical scheme, as grid \textit{systems} are the main focus of this thesis.


\begin{figure}[ht!]
	\centering
	\includegraphics[width=0.6\textwidth]{morton-multiple.pdf}
	\caption[Four resolutions of Morton codes]{
		The first four resolutions of Morton codes for a quadtree.
		(a)--(d) show resolutions 1--4, respectively.
		Modified from~~\cite{morton-multiple}; original image courtesy of David Eppstein -- CC BY-SA 3.0
	}
	\label{fig:morton-multiple}
\end{figure}


Figure~\ref{fig:morton-multiple} demonstrates Morton coding for four resolutions of a conventional Euclidean quadtree.
Indices are assigned consecutively, starting at zero, to cells in the order the curve passes through them.
The resulting indices are hierarchical, where the index of a cell is that of its parent with its local index---obtained relative to its parent---appended.
While shown for a quadtree (2D), Morton codes generalize to any integer dimension $n$.
In this case, each cell has $2^n$ children, which means $n$ bits are needed to represent each uniquely.
Thus, from a given cell index, the resolution of the grid that cell appears at is the bit width of the index divided by $n$.
For a fixed-width representation of indices, a leaded bit set to one marks the start of the actual index.


\begin{figure}[htp!]
	\centering
	\includegraphics[width=\textwidth]{morton-interleave.pdf}
	\caption[Morton codes by bit-interleaving]{
		Third resolution Morton codes and their respective coordinate indices.
		Note how the Morton codes are obtained by interleaving the bits of the coordinate indices.
		In this figure, the $x$ coordinate is traversed first by the curve, so it is the lowest order bit in the Morton code.
		Image courtesy of David Eppstein~\cite{morton-interleave} -- CC BY-SA 3.0
	}
	\label{fig:morton-interleave}
\end{figure}


One benefit of Morton codes over more local space-filling curves---such as the Hilbert curve---is the ease at which a multi-dimensional index is encoded and vice versa.
As demonstrated in Figure~\ref{fig:morton-interleave}, the Morton code is obtained simply by interleaving the bits of the coordinate indices; likewise, unweaving the bits of a Morton code gives the coordinate indices.
While these are not constant-time operation in general, magic numbers and lookup tables allow them to be done efficiently and in constant time for a fixed bit width~\cite{bit twiddle, libmorton}.


\begin{figure}[ht!]
	\centering
	\includegraphics[width=\textwidth]{sdog-dmc.pdf}
	\caption[Degenerate Morton codes for the different SDOG cell types]{
		Degenerate Morton codes for (a) SG cells, (b) LG cells, and (c) NG cells.
	}
	\label{fig:sdog-dmc}
\end{figure}


Due to the semiregular degenerate nature of SDOG, Morton coding must be modified for use with the grid system.
First, Morton coding for a cell's children is done as if refinement is entirely regular.
For NG cells, refinement \textit{is} regular, and no modifications are needed.
However, for SG and LG cells, some of these codes will refer to the same cell.
In these cases, we merge duplicate codes with the lower value kept.
We call this the degenerate Morton code (DMC).
Figure~\ref{fig:sdog-dmc} shows the child codes of cells for each SDOG cell type.
In this scheme, the different spherical coordinates are traversed in the order (1) longitude---small to large (2) latitude---small to large (3) radius---large to small.
Finally, to distinguish between the eight octants, each is given a unique identifier: the octant code.
The full index of an SDOG cell consists of the octant code and DMC, concatenated, along with a leading one for fixed-width representations.
For the remainder of this chapter, we assume the use of a fixed-width integer for representing SDOG indices.


From the above definition, we know the number of bits needed to represent an SDOG index at refinement level $k$ is $3k + 4$.
Likewise, given an index with width $\omega$, the refinement level of that cell is $(\omega - 4) / 3$.
We use this property below to obtain $k$ for the decoding algorithms, implicitly.


\subsection{Hierarchical Algorithms}
We first give a brief overview of the hierarchical coding algorithms for SDOG, as these will be the baseline for evaluating our proposed ones.
Hierarchical coding works by traversing the grid system one resolution at a time, using the refinement rules for the relevant cell at each iteration.
As a result, these types of algorithms are linear on the level of refinement.
However, because they use refinement rules directly, they are trivially modified to work for our SDOG modifications by simply changing the refinement used in the algorithms accordingly.


\subsubsection{Encoding}
The algorithm for hierarchical point encoding with SDOG is given in Algorithm~\ref{alg:encode}.
The input is a point $p$ and resolution $k$; the output is the index $i$ of the cell that contains $p$ at $k$.


\begin{algorithm}
	\caption{Hierarchical point encoding for SDOG}
	
	\begin{algorithmic}
		
		\STATE determine which octant contains $p$
		\STATE cellBoundaries $\leftarrow$ boundaries of octant
		\STATE currCellType $\leftarrow$ SG
		\STATE $i \leftarrow \operatorname{append}(1, \mathrm{octantCode})$
		
		\FOR{$k$ iterations}
		\STATE use refinement rules for currCellType with cellBoundaries to find child cells
		\STATE determine which child contains $p$
		\STATE cellBoundaries $\leftarrow$ boundaries of child
		\STATE currCellType $\leftarrow$ type of child
		\STATE $i \leftarrow \operatorname{append}(i, \mathrm{child~index})$
		\ENDFOR
		\RETURN $i$
		
	\end{algorithmic}
	\label{alg:encode}
\end{algorithm}


\subsubsection{Decoding}
The algorithm for hierarchical decoding with SDOG is given in Algorithm~\ref{alg:decode}.
The input is an index $i$; the output is the cell boundaries of $i$.


\begin{algorithm}
	\caption{Hierarchical cell decoding for SDOG}
	
	\begin{algorithmic}
		
		\STATE determine octant from $i$
		\STATE cellBoundaries $\leftarrow$ boundaries of octant
		\STATE currCellType $\leftarrow$ SG
		\STATE remove highest four bits of $i$
		
		\FOR{$k$ iterations}
		\STATE use refinement rules for currCellType with cellBoundaries to find child cells
		\STATE $c \leftarrow$ highest three bits of $i$
		\STATE remove highest three bits of $i$
		\STATE determine which child cell matches $c$
		\STATE cellBoundaries $\leftarrow$ boundaries of $c$
		\STATE currCellType $\leftarrow$ type of $c$
		\ENDFOR
		\RETURN cellBoundaries
		
	\end{algorithmic}
	\label{alg:decode}
\end{algorithm}


\subsection{Direct Algorithms}
For a uniform grid, the coordinate indices of the cell that contain a point are obtained trivially in constant time.
Likewise, the maximum and minimum coordinates of a cell are also easily computed from a coordinate index.
For these operations, the necessary variables are the number of cells and the range of values in each coordinate dimension.
We also know that the semiregular regions of SDOG are uniform when using conventional refinement rules.
Thus, if we determine the relevant semiregular region and the needed properties of said region, we can apply direct coding algorithms for SDOG, with bit interleaving and unweaving giving the full DMC.


Under regular octree-based refinement, the number of cells in each coordinate direction is $2^k$.
Each increasing shell in SDOG halves the number of cells in the latitude and longitude coordinates.
Furthermore, each increasing zone further halves the number of cells in the longitude coordinate.
Since a DMC is relative to an octant, the range of coordinate values for direct coding are the ranges of the octant itself.
Therefore, all that we need for direct coding is the shell and zone that contain the point or cell being considered.


\subsubsection{Encoding}
The inputs and outputs of direct encoding are the same as their hierarchical counterpart.
First, we find the octant that contains $p$.
The three coordinates of $p$ are then normalized within the range of the octant with $\hat{r} = r / R_\mathrm{max}$, $\hat{\varphi} = \pm (2\varphi) / \pi$, and $\hat{\lambda} = 2 (\lambda - \lambda_0) / \pi$ where $\lambda_0$ is the minimum longitude of the octant.
We then calculate the shell and zone that contain $p$ the same as in Chapter~\ref{chap:mapping}: $s = \lfloor \log_{0.5} \hat{r} \rfloor$ and $z = \lfloor \log_{0.5} ( 1 - \hat{\varphi} ) \rfloor$.


The number of latitude division will be $2^k$ divided by $2^s$; however, the number of divisions will always be at least one.
Thus, we introduce variable $k_\varphi = \min ( s, k )$.
Similarly, the number of longitude division will $2^k$ divided by $2^{s+z}$, but again, will always be at least one.
We introduce a second variable $k_\lambda = \min ( s + z, k )$.


Finally, we calculate coordinate indices, making sure to account for the direction of each coordinate in the DMC for SDOG.
Let the subscript $i$ refer to the index the coordinate, then
%
\begin{equation*}
r_i = 2^k \cdot ( 1 - \hat{r} ),
\end{equation*}
%
\begin{equation*}
\varphi_i = 2^{k - k_\varphi} \cdot \hat{\varphi}, \quad \text{and}
\end{equation*}
%
\begin{equation*}
\lambda_i = 2^{k - k_\lambda} \cdot \hat{\lambda}.
\end{equation*}
%
The DMC, then, is the Morton interleaving of $\lambda_i$, $\varphi_i$, and $r_i$ (in that order); the full index is the octant code and DMC concatenated with the preceding bit set.


\subsubsection{Decoding}
The inputs and outputs of the direct decoding are the same as its hierarchical counterpart.
First, we get the octant code and DMC from $i$.
The DMC is then unwoven to get the coordinate indices $\lambda_i$, $\varphi_i$, and $r_i$.


We now decode the coordinate indices one at a time.
As the number of radial division is never modified, we start by decoding the radial index: 
%
\begin{equation*}
\hat{r}_\mathrm{max} = 1 - \frac{r_i}{2^k}, \quad \text{and}
\end{equation*}
%
\begin{equation*}
\hat{r}_\mathrm{min} = 1 - \frac{r_i + 1}{2^k}
\end{equation*}
%
With this, we can now determine the shell that contains the cell being decoded.
We use $\hat{r}_\mathrm{max}$ as opposed to $\hat{r}_\mathrm{min}$, as the latter gives the inner shell if on the boundary. Thus, $s = \lfloor \log_{0.5} \hat{r}_\mathrm{max} \rfloor$.
Just as with encoding, we define $k_\varphi = \min ( s, k )$.
We now have the needed information to decode latitude:
%
\begin{equation*}
\hat{\varphi}_\mathrm{max} = \frac{\varphi_i + 1}{2^{k - k_\varphi}}, \quad \text{and}
\end{equation*}
%
\begin{equation*}
\hat{\varphi}_\mathrm{min} = \frac{\varphi_i}{2^{k - k_\varphi}}.
\end{equation*}
%
Likewise, we can now determine the zone that contains the cell.
Opposite of radius, $\hat{\varphi}_\mathrm{max}$ now gives the higher zone if on the boundary, so we use $\hat{\varphi}_\mathrm{min}$ and get $z = \lfloor \log_{0.5} ( 1 - \hat{\varphi}_\mathrm{min} ) \rfloor$.
Again, the same as encoding, we define $k_\lambda = \min ( s + z, k )$.
Finally, we decode longitude:
%
\begin{equation*}
\hat{\lambda}_\mathrm{max} = \frac{\lambda_i + 1}{2^{k - k_\lambda}}, \quad \text{and}
\end{equation*}
%
\begin{equation*}
\hat{\lambda}_\mathrm{min} = \frac{\lambda_i}{2^{k - k_\lambda}}.
\end{equation*}
%
The last step is get the bounds of the octant from the octant code and convert the normalized values to actual ones.


\subsubsection{For Modified SDOG}
These direct algorithms only work for conventional SDOG due to the requirement of uniform spacing of grid divisions.
As described in Chapter~\ref{mapping}, however, the mapping functions allow these algorithms to be used with the modified grids by mapping them to conventional SDOG.
For encoding, the point $p$ must be forward mapped before encoding.
For decoding, the output ranges must be inverse mapped after decoding.
In both cases, there is overlap in the computations done by the coding algorithm and associated mapping functions, so care should be taken during implementation to avoid redundant computation.


\subsection{Runtime Comparison}
To evaluate the usefulness of our direct coding algorithms, we should compare their runtime against the hierarchical counterparts.
To do so, we have implemented the four algorithms and the mapping functions presented in Chapter~\ref{chap:mapping} in C++.
We also used these implementations to experimentally verify the correctness of the direct algorithms by comparing their output to the hierarchical ones.


The combination of two algorithmic approaches (hierarchical vs. direct) and four grids (SDOG and the three modifications in Chapter~\ref{chap:sdog}) result in eight total algorithms to compare for both encoding and decoding.
For simplicity, we only benchmark the DMC portion of coding.
We first generate one million points randomly distributed within an SDOG octant.
For each resolution being benchmarked, we then time each of the encoding algorithms using the generated points.
The resulting indices are then used to time each of the decoding algorithms in the same manner.
We time resolutions $1 \le k \le 21$, as 21 is the highest resolution \textit{without} an octant code that can be represented by a 64-bit integer.
We use the libmorton library~\cite{libmorton} to perform efficient bit-interleaving and unweaving.


\begin{figure}[htp!]
	\centering
	\includegraphics[width=0.8\textwidth]{point-to-index.pdf}
	\caption[Runtime comparison of SDOG point encoding algorithms]{
		A caption will go here.
		The caption may be long.
		This is text that is filling space so that this placeholder caption is longer than if the text was not here.
		Caption caption caption.
		Now the text will repeat...
		A caption will go here.
		The caption may be long.
	}
	\label{fig:point-to-index}
\end{figure}


\begin{figure}[htp!]
	\centering
	\includegraphics[width=0.8\textwidth]{index-to-range.pdf}
	\caption[Runtime comparison of SDOG decoding algorithms]{
		A caption will go here.
		The caption may be long.
		This is text that is filling space so that this placeholder caption is longer than if the text was not here.
		Caption caption caption.
		Now the text will repeat...
		A caption will go here.
		The caption may be long.
	}
	\label{fig:index-to-range}
\end{figure}


Figures~\ref{fig:point-to-index} and \ref{fig:index-to-range} show the benchmarking results for encoding and decoding, respectively.
In order to reduce noise, these charts show the average of two evaluations of the benchmarking.
As is expected, the hierarchical algorithms are linear on $k$ and the direct algorithms (mostly) constant on $k$.


For the hierarchical algorithms, the difference in runtime between the different grids is determined by the complexity of calculating splitting surfaces for cells.
For hierarchical encoding and decoding, SDOG is the most efficient closely followed by the latitude method; the volume method is significantly slower than these two, and the balanced method significantly slower than the volume one.
For the direct algorithms, this difference is determined by the complexity of evaluating the mapping functions.
For direct encoding, SDOG is most efficient, then volume closely followed by latitude, and then balanced.
Decoding is slightly different, with latitude and volume swapping places in the ordering.


In general, the hierarchical decoding algorithms are slightly quicker than their encoding counterparts.
The reasons for this are not entirely clear; however, it seems to imply that determining which child cell contains a point is slightly more expensive than setting the child cell dimensions based on a given code.
For the direct algorithms, the opposite holds, and the encoding algorithm is the quicker of the two.
The reason for this is the encoding algorithm only computes three values (an index for each coordinate), whereas the decoding must compute twice as many (a maximum \textit{and} minimum for each coordinate).
Furthermore, for the modified grids using the mapping functions, this means that decoding also requires twice as many uses of these functions.


Overall, the direct algorithms are all more efficient than their hierarchical counterpart for a large enough value of $k$.
Thus, a sophisticated implementation could determine which approach to use (hierarchical or direct) for a given input, depending on $k$.
However, benchmarking on a variety of platforms in different conditions would be needed to determine the best values to use for the switch.
Table~\ref{tab:hierarch-vs-direct} summarizes the lowest value of $k$ such that the direct algorithm is more efficient than the hierarchical for each pair of algorithms in \textit{our} benchmarking.


\begin{table}[htp!]
	\centering
	\caption[Resolution at which direct coding becomes more efficient than hierarchical]{
		The resolution ($k$) at which our direct coding algorithms become more efficient than their hierarchical counterparts
	}
	\begin{tabular}{@{} c c c c c @{}}
		\toprule
		& SDOG & Latitude & Balanced & Volume \\ \midrule
		Encoding & 6    & 7        & 4        & 3      \\
		Decoding & 11   & 13       & 5        & 5      \\ \bottomrule
	\end{tabular}
	\label{tab:hierarch-vs-direct}
\end{table}


A final note is that runtime for direct decoding of the modified grids grows until about resolution four, where it then levels off to constant.
The reason for this is subtle.
In the decoding algorithm, values of $s$ and $z$ are calculated from the bounds of the cell being decoded.
Therefore, their values are bounded by $k$.
However, $s$ and $z$ are used as exponents when calculating $\ell$ and $u$ values, which is faster for lower exponents.
Thus, low values of $k$ have lower maximum (and average) exponents and, therefore, slightly lower runtime.
This same effect does not appear in the encoding algorithms since $s$ and $z$ are calculated directly from $p$ with no respect to $k$.


\subsection{Other Indexing Operations}
Parent trivial.
Children trivial if have cell type. SG if $r_i = 2^k - 1$. LG if $\varphi_i = 2^{k - k_\varphi} - 1$.
Neighbours are tricky...


\section{Extension Method}


\subsection{Encoding}


\subsection{Decoding}


\subsection{Other Indexing Operations}
An important component of a conventional DGGS is the indexing scheme for cells.
Indices in a DGGS are used to not only identify and linearize cells but also as a means of navigating the grid for various spatial queries~\cite{alderson2020digital}.
To this end, it is important to be able to perform certain operations on said indices efficiently.
The most fundamental of these operations are parent queries, which return the parent (or with non-congruent refinement, \textit{parents}) of a given cell; child queries, which return the children of the cell; and neighbour queries, which return cells that share an edge (or in 3D a face) with the cell.
These operations serve as the building blocks for more complex geospatial queries done with the grid system, such as region growing, data convolution and correlation, feature rasterization, and buffering.
Because of this, creating suitable indexing for a 3D DGGS is an essential task.


With our method---similar to encoding and decoding---we define these operations in terms of surface and radial components.
This split not only simplifies the problem of indexing but also ensures the 3D indexing is consistent with that of the input DGGS.
Referring back to Figures~\ref{fig:indexing} and \ref{fig:3d-coding}, we let $i_s$ be the surface index of a cell and $i_\ell$ be the layer index.
For each of these components, we assume there is a corresponding parent, child, and neighbour operation.
For the surface index, this comes directly from the input DGGS indexing, whereas for the layer index, these would need to be defined.
Using the component operations, we define the corresponding 3D operations as follows.


\subsubsection{Layer Algorithms}
Parent, child, and neighbours for layers.


\subsubsection{Combined Algorithms}
Combine operations of layers and input to make full 3D operations.


\paragraph{Parents}
The parent(s) of a cell depend on if the layer of the cell and its parent layer have the same, or different, values of $k_s$.
Let $i_\ell' = \operatorname{parent}(i_\ell)$; if the value of $k_s$ is the same, then the single parent is simply $(i_s, i_\ell')$.
In most cases, the value of $k_s$ for $i_\ell'$ is some number $m$ (often one, but not always) less than that of $i_\ell$.
In this case, the parent(s) are given by $\operatorname{parents}^m(i_s) \times i_\ell$.


\paragraph{Children} The children of a cell depend on if the cell belongs to a central or normal layer.
For normal layers, the set of children is simply $\operatorname{children}(i_s) \times \operatorname{children}(i_\ell)$.
For central layers, the child who belongs to the new central layer must be distinguished from the other child layer(s).
Call the index of the new central layer $c_\ell$; then, this child is given by $(i_s, c_\ell)$.
Let $ N_\ell$ give the set of the other children layer indices (normal layers).
These layers have the surface refinement applied $w$ times, so the resulting children are $\operatorname{children}^w(i_s) \times N_\ell$


\paragraph{Neighbours} We split neighbours into three categories: neighbours in the same layers as the cell, neighbours in the layer above the cell, and neighbours in the layer below the cell.
If a cell belongs to the outermost or innermost (central) layer, then it will not have neighbours in the layer above or below, respectively.
Neighbours in the same layer are simply $\operatorname{neighbours}(i_s) \times i_\ell$.
Let $i_\ell^+$ be the layer above $i_\ell$ and $i_\ell^-$ be the layer below.
If $i_\ell^+$ has the same value of $k_s$ as $i_\ell$, then the single neighbour above is $(i_s, i_\ell^+)$.
In the other case, where the value of $k_s$ for $i_\ell^+$ is some number $m$ greater than that of $i_\ell$, the neighbours are given by $\operatorname{children}^m(i_s) \times i_\ell^+$.
Likewise, if $i_\ell^-$ has the same value of $k_s$ as $i_\ell$, there is one neighbour below given by $(i_s, i_\ell^-)$.
In the case that the value of $k_s$ for $i_\ell^-$ is some number $m$ less than that of $i_\ell$, the neighbours are given by $\operatorname{parents}^m(i_s) \times i_\ell^-$

\section{Summary}
A summary of everything will go here.